{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "CLASSES = 10 # note: could have inferred this automatically from the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import save_submission,load_data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# \n",
    "import datetime\n",
    "from sys import stdout\n",
    "from softmaxSKL import softmaxModel\n",
    "import pprint\n",
    "# I have included this file\n",
    "# I wrote it in order to ease making changes\n",
    "from softmaxSKL import softmaxModel\n",
    "# Plotting\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_fn = \"NOISY_MNIST_SUBSETS.h5\"\n",
    "# Load training data\n",
    "Xsmall,Ysmall = load_data(data_fn, \"small_train\")\n",
    "Xlarge,Ylarge = load_data(data_fn, \"large_train\")\n",
    "# Load validation data\n",
    "Xval,Yval = load_data(data_fn, \"val\")\n",
    "# Load competition data\n",
    "kaggleX = load_data(data_fn, 'kaggle')\n",
    "\n",
    "# Mean center the data\n",
    "Xsmall = Xsmall - Xsmall.mean(0)\n",
    "Xval = Xval - Xval.mean(0)\n",
    "kaggleX = kaggleX - kaggleX.mean(0)\n",
    "\n",
    "# Save standout to file\n",
    "now = datetime.datetime.now()\n",
    "stdout = open(\"Output/output\" + str(now.hour) + str(now.minute) + \".txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smallOpt = {\n",
    "    'eta': [2, 1.5, 1], \n",
    "    'maxiter': [10000],  \n",
    "    'batch_size': [2, 3, 4], \n",
    "    'etadrop': [0.4, 0.3, 0.2],\n",
    "    'eta_frac': [0.8, 0.7],\n",
    "    'lambda_' : [0.1, 0.05, .025]       \n",
    "}\n",
    "\n",
    "pprint.pprint(smallOpt, width=1)\n",
    "\n",
    "gsSmall = GridSearchCV(softmaxModel(), smallOpt, cv=5, n_jobs=-1, \n",
    "                        verbose=1)\n",
    "gsSmall.fit(Xsmall, Ysmall)\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "pprint.pprint(gs.best_params_, width=1)\n",
    "\n",
    "# Test on validation\n",
    "y_true, y_pred = Yval.argmax(-1), gs.predict(Xval)\n",
    "# Output Results\n",
    "print(\"\\nAccuracy_Score\")\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "# Classifcation Report\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(\"\\n Confusion Matrix\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Kaggle Small\n",
    "kaggleSmall = gsSmall.predict(kaggleX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0 batch loss: 4.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:11: RuntimeWarning: overflow encountered in exp\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:12: RuntimeWarning: overflow encountered in exp\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:12: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2000 batch loss: nan\n",
      "    4000 batch loss: nan\n",
      "    6000 batch loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0384aaf359b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# by default, it would copy it by reference, i.e., it would make a new pointer to the same data, so later changing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# the contents would change the \"copied\" version as well. deepcopy actually makes a copy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalErr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainErr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunTrainVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXsmall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYsmall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0msmall_trained_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_err\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalErr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_err\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainErr\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'small train set model: -> lambda= %.4f, train error: %.2f, val error: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainErr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalErr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d717ac6f12dc>\u001b[0m in \u001b[0;36mrunTrainVal\u001b[0;34m(X, Y, model, Xval, Yval, trainopt)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtrainopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'display_iter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{:8} batch loss: {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-cdb55c20c346>\u001b[0m in \u001b[0;36mmodelUpdate\u001b[0;34m(X, Y, model, lambda_, eta)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#     print(weight[:5,:5])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mregTermWeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mregTermBias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                      \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sys.stdout = open(\"Large/output\" + str(now.hour) + str(now.minute) + \".txt\", \"w\")\n",
    "\n",
    "# -- training options; these are suggestions, feel free to experiment\n",
    "bigOpt = {\n",
    "    'eta': [0.6],  \n",
    "    'maxiter': [10000],\n",
    "    'batch_size': [70, 60, 50], \n",
    "    'etadrop': [0.95],\n",
    "    'eta_frac': [0.18, .2, 0.22],  \n",
    "    'lambda_' : [0.015, 0.01, 0.05] \n",
    "}\n",
    "\n",
    "pprint.pprint(bigOpt, width=1)\n",
    "\n",
    "gsLarge = RandomizedSearchCV(softmaxModel(), bigOpt, cv=5, n_jobs=-1, verbose=1, n_iter=144)\n",
    "gsLarge.fit(Xlarge, Ylarge)\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "pprint.pprint(gs.best_params_, width=1)\n",
    "# Test on validation\n",
    "y_true, y_pred = Yval.argmax(-1), gs.predict(Xval)\n",
    "print(\"\\nAccuracy_Score\")\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"\\n Confusion Matrix\\n\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "# Make Predictions\n",
    "kaggleLarge = gsLarge.predict(kaggleX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kaggle \n",
    "\n",
    "# Save results\n",
    "save_submission('submission-large.csv',  kaggleLarge)\n",
    "# Save results\n",
    "save_submission('submission-small.csv',  kaggleSmall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_small_trained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b58f13364d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#for model trained on small_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkaggleX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mkaggleYhat_small\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkaggleX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_small_trained_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msave_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission-small.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkaggleYhat_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_small_trained_model' is not defined"
     ]
    }
   ],
   "source": [
    "#Generate a Kaggle submission file using `model`\n",
    "\n",
    "#for model trained on small_train\n",
    "kaggleX = load_data(data_fn, 'kaggle')\n",
    "kaggleYhat_small = predict(kaggleX, best_small_trained_model).argmax(-1)\n",
    "save_submission('submission-small.csv', kaggleYhat_small)\n",
    "\n",
    "#for model trained on large_train\n",
    "kaggleYhat_large = predict(kaggleX, best_large_trained_model).argmax(-1)\n",
    "save_submission('submission-large.csv', kaggleYhat_large)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
